# Web Scraping Series with Python Scrapy

This repository contains the source code of web crawlers that can scrape various websites and extract useful data using Python Scrapy. The web crawlers are created as part of a web scraping series on LinkedIn, where I explain how to use Scrapy to scrape different types of websites and save the data in different formats.

## How to use

To use the web crawlers, you need to have Python 3 and Scrapy installed on your system. You can install Scrapy using pip:

```bash
pip install scrapy
```

You also need to clone this repository to your local machine

Then, you can navigate to the directory of the web crawler that you want to use and run it using the I have completed the readme for the directory containing the files of codes used in the web scraping series. Here's the rest of the readme:

## Feedback and requests
I hope you find this web scraping series useful and enjoyable. If you do, please give this repository a star and share it with your friends. I would love to hear your feedback and suggestions on how to improve this series. You can send me an email at jesufemioresanya03@gmail.com.

Also, if you have a specific website that you want me to scrape for you, please email me the link of the website and the data that you want to extract. I'll do my best to create a spider for it and share it with you in the next episode.

Thank you for your support and stay tuned for more web scraping fun!
