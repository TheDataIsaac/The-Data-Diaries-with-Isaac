{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669e39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae69f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas option to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "job_data = pd.read_csv(\"gsearch_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59b2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      " Unnamed: 0               int64\n",
      "index                    int64\n",
      "title                   object\n",
      "company_name            object\n",
      "location                object\n",
      "via                     object\n",
      "description             object\n",
      "extensions              object\n",
      "job_id                  object\n",
      "thumbnail               object\n",
      "posted_at               object\n",
      "schedule_type           object\n",
      "work_from_home          object\n",
      "salary                  object\n",
      "search_term             object\n",
      "date_time               object\n",
      "search_location         object\n",
      "commute_time           float64\n",
      "salary_pay              object\n",
      "salary_rate             object\n",
      "salary_avg             float64\n",
      "salary_min             float64\n",
      "salary_max             float64\n",
      "salary_hourly          float64\n",
      "salary_yearly          float64\n",
      "salary_standardized    float64\n",
      "description_tokens      object\n",
      "dtype: object\n",
      "Dataset Shape: (27389, 27)\n",
      "Column Names: Index(['Unnamed: 0', 'index', 'title', 'company_name', 'location', 'via',\n",
      "       'description', 'extensions', 'job_id', 'thumbnail', 'posted_at',\n",
      "       'schedule_type', 'work_from_home', 'salary', 'search_term', 'date_time',\n",
      "       'search_location', 'commute_time', 'salary_pay', 'salary_rate',\n",
      "       'salary_avg', 'salary_min', 'salary_max', 'salary_hourly',\n",
      "       'salary_yearly', 'salary_standardized', 'description_tokens'],\n",
      "      dtype='object')\n",
      "Descriptive Statistics:\n",
      "          Unnamed: 0         index  commute_time     salary_avg     salary_min  \\\n",
      "count  27389.000000  27389.000000           0.0    5007.000000    4708.000000   \n",
      "mean   13694.000000   1113.448574           NaN   38202.596855   32230.298970   \n",
      "std     7906.667598    699.765856           NaN   52342.024545   44057.798078   \n",
      "min        0.000000      0.000000           NaN       9.000000       8.000000   \n",
      "25%     6847.000000    526.000000           NaN      32.437500      20.000000   \n",
      "50%    13694.000000   1063.000000           NaN      60.000000      49.000000   \n",
      "75%    20541.000000   1634.000000           NaN   90000.000000   77000.000000   \n",
      "max    27388.000000   3054.000000           NaN  233500.000000  215000.000000   \n",
      "\n",
      "          salary_max  salary_hourly  salary_yearly  salary_standardized  \n",
      "count    4708.000000    3114.000000    1884.000000          5007.000000  \n",
      "mean    45521.591393      43.529758  101427.956895         94606.090272  \n",
      "std     62133.596100      23.156382   29512.244451         42416.184312  \n",
      "min        10.000000       9.000000   29289.840000         18720.000000  \n",
      "25%        45.000000      27.500000   85000.000000         64480.000000  \n",
      "50%        75.000000      38.500000   96500.000000         93778.195000  \n",
      "75%    110000.000000      57.500000  112500.000000        119600.000000  \n",
      "max    283000.000000     300.000000  233500.000000        624000.000000  \n",
      "Missing Values:\n",
      " Unnamed: 0                 0\n",
      "index                      0\n",
      "title                      0\n",
      "company_name               0\n",
      "location                  19\n",
      "via                        9\n",
      "description                0\n",
      "extensions                 0\n",
      "job_id                     0\n",
      "thumbnail              12684\n",
      "posted_at                  0\n",
      "schedule_type            174\n",
      "work_from_home         15420\n",
      "salary                 22382\n",
      "search_term                0\n",
      "date_time                  0\n",
      "search_location            0\n",
      "commute_time           27389\n",
      "salary_pay             22382\n",
      "salary_rate            22382\n",
      "salary_avg             22382\n",
      "salary_min             22681\n",
      "salary_max             22681\n",
      "salary_hourly          24275\n",
      "salary_yearly          25505\n",
      "salary_standardized    22382\n",
      "description_tokens         0\n",
      "dtype: int64\n",
      "Salary Rate Value Counts:\n",
      " an hour    3114\n",
      "a year     1884\n",
      "a month       9\n",
      "Name: salary_rate, dtype: int64\n",
      "Company Name Value Counts:\n",
      " Upwork                     4277\n",
      "Walmart                     937\n",
      "EDWARD JONES                730\n",
      "Corporate                   609\n",
      "Talentify.io                518\n",
      "                           ... \n",
      "Energy Service Experts        1\n",
      "Rogue Recruitment             1\n",
      "RGA Reinsurance Company       1\n",
      "Movement Labs                 1\n",
      "Techdash Telecom              1\n",
      "Name: company_name, Length: 6838, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of the DataFrame\n",
    "job_data.head()\n",
    "\n",
    "# Display basic dataset information\n",
    "print(\"Data Types:\\n\", job_data.dtypes)\n",
    "print(\"Dataset Shape:\", job_data.shape)\n",
    "print(\"Column Names:\", job_data.columns)\n",
    "\n",
    "# Descriptive statistics for numerical columns\n",
    "print(\"Descriptive Statistics:\\n\", job_data.describe())\n",
    "\n",
    "# Check for missing values and display their sums\n",
    "print(\"Missing Values:\\n\", job_data.isna().sum())\n",
    "\n",
    "# Display value counts for the \"salary_rate\" column\n",
    "print(\"Salary Rate Value Counts:\\n\", job_data[\"salary_rate\"].value_counts())\n",
    "\n",
    "# Display value counts for the \"company_name\" column\n",
    "print(\"Company Name Value Counts:\\n\", job_data[\"company_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4af233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace True with 1 and NaN with 0 in the \"work_from_home\" column\n",
    "job_data[\"work_from_home\"] = job_data[\"work_from_home\"].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e23afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"via \" from the \"via\" column to clean the data\n",
    "job_data[\"via\"] = job_data[\"via\"].str.replace(\"via \", \"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd14c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = [\"Unnamed: 0\", \"index\",\"description\", \"thumbnail\", \"posted_at\", \"commute_time\", \"salary\", \"salary_hourly\", \"salary_yearly\"]\n",
    "\n",
    "# Drop the specified columns\n",
    "job_data.drop(columns=columns_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a89417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate job_id Values: 20\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated \"job_id\" values and print the sum\n",
    "duplicates = job_data[\"job_id\"].duplicated().sum()\n",
    "print(\"Duplicate job_id Values:\", duplicates)\n",
    "\n",
    "# Drop duplicate rows based on the \"job_id\" column\n",
    "job_data.drop_duplicates(subset=\"job_id\", inplace=True)\n",
    "\n",
    "# Reorder columns with \"job_id\" as the first column\n",
    "column_names = job_data.columns.tolist()\n",
    "column_names.remove(\"job_id\")\n",
    "column_names.insert(0, \"job_id\")\n",
    "job_data = job_data[column_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bd8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"date_time\" column to datetime\n",
    "job_data[\"date_time\"] = pd.to_datetime(job_data[\"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06bcb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the \"date_time\" column as \"yyyy-mm-dd\" and store it in the same column\n",
    "job_data[\"date_time\"] = job_data[\"date_time\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Rename the \"date_time\" column to \"date\"\n",
    "job_data.rename(columns={\"date_time\": \"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b64683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"salary_info_status\" based on \"salary_pay\" column\n",
    "job_data[\"salary_info_status\"] = job_data[\"salary_pay\"].isna().replace({True: \"Not Specified\", False: \"Available\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ca3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty \"city\" and \"state\" columns\n",
    "job_data.insert(3, \"city\", \"\")\n",
    "job_data.insert(4, \"state\", \"\")\n",
    "\n",
    "# Split the \"Location\" column into \"city\" and \"state\" columns where possible\n",
    "for index, row in job_data.iterrows():\n",
    "    location = row['location']\n",
    "    if pd.notna(location):\n",
    "        try:\n",
    "            city, state = location.strip().split(', ')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            job_data.at[index, 'city'] = city\n",
    "            job_data.at[index, 'state'] = state\n",
    "\n",
    "# Drop the original \"location\" column\n",
    "job_data.drop(\"location\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f57473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where state has more than 2 characters (invalid values)\n",
    "job_data.drop(job_data[job_data.state.str.len() > 2].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15facdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'title_group' column with 'Other'\n",
    "job_data['title_group'] = 'Other' \n",
    "\n",
    "# Define the conditions and corresponding values\n",
    "conditions = [\n",
    "    (job_data['title'].str.contains(r'analy(?:z|s|t)(?:e|is|ic|t)s?', case=False) &\n",
    "     job_data['title'].str.contains(r'engineerg?', case=False)),\n",
    "    (job_data['title'].str.contains(r'analy(?:z|s|t)(?:e|is|ic|t)s?', case=False) &\n",
    "     job_data['title'].str.contains(r'scientists?|sciences?', case=False)),\n",
    "    (job_data['title'].str.contains(r'engineerg?', case=False) &\n",
    "     job_data['title'].str.contains(r'scientists?|sciences?', case=False)),\n",
    "    job_data['title'].str.contains(r'analy(?:z|s|t)(?:e|is|ic|t)s?', case=False),\n",
    "    job_data['title'].str.contains(r'engineerg?', case=False),\n",
    "    job_data['title'].str.contains(r'scientists?|sciences?', case=False)\n",
    "]\n",
    "\n",
    "# Define the corresponding values for each condition\n",
    "values = [\n",
    "    'Analyst/Engineer',\n",
    "    'Analyst/Scientist',\n",
    "    'Engineer/Scientist',\n",
    "    'Analyst',\n",
    "    'Engineer',\n",
    "    'Scientist'\n",
    "]\n",
    "\n",
    "# Use numpy's select function to apply the conditions and assign values accordingly\n",
    "job_data['title_group'] = np.select(conditions, values, default='Other')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa391e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv(\"jobdata_processed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c25e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
